{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import platform\n",
    "import psutil\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "def get_config():\n",
    "    return {\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"batch_size\": 32,\n",
    "        \"n_estimators\": 10,\n",
    "        \"max_depth\": 3\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define training function\n",
    "def train_model(config):\n",
    "    data = load_iris()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=config[\"n_estimators\"], max_depth=config[\"max_depth\"], random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average='macro') # Weighted for multi-class  \n",
    "    recall = recall_score(y_test, predictions, average='weighted')  # Weighted for multi-class\n",
    "    f1= f1_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "    return model, accuracy, predictions, y_test, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logging function\n",
    "def log_model_mlflow(config, model, accuracy,predictions, y_test, precision,recall, f1):\n",
    "    mlflow.set_tracking_uri(uri='http://127.0.0.1:5000/')\n",
    "    mlflow.set_experiment('iris Classifier Insights')\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Log parameters\n",
    "        for param_name, param_value in config.items():\n",
    "            mlflow.log_param(param_name, param_value)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "        mlflow.log_metric('precision', precision)\n",
    "        mlflow.log_metric('recall', recall)\n",
    "        mlflow.log_metric('f1', f1)\n",
    "        loss = np.mean(np.square(y_test - predictions))  # Mean Squared Error\n",
    "        mlflow.log_metric('loss', loss)\n",
    "\n",
    "        # Log system information\n",
    "        mlflow.log_param(\"system_os\", platform.system())\n",
    "        mlflow.log_param(\"system_processor\", platform.processor())\n",
    "        mlflow.log_param(\"system_ram\", f\"{psutil.virtual_memory().total / 1e9:.2f} GB\")\n",
    "        mlflow.log_param(\"cpu_count\", os.cpu_count())\n",
    "        mlflow.log_param(\"python_version\", platform.python_version())\n",
    "\n",
    "        # Log detailed hardware information\n",
    "        cpu_freq = psutil.cpu_freq().max if psutil.cpu_freq() else \"Unknown\"\n",
    "        disk_usage = psutil.disk_usage('/').total / 1e9  # Disk size in GB\n",
    "        mlflow.log_param(\"cpu_max_frequency_MHz\", cpu_freq)\n",
    "        mlflow.log_param(\"disk_total_GB\", f\"{disk_usage:.2f}\")\n",
    "\n",
    "        # Measure resource usage\n",
    "        start_time = time.time()\n",
    "        initial_memory = psutil.Process(os.getpid()).memory_info().rss / 1e6  # Memory in MB\n",
    "\n",
    "        runtime = time.time() - start_time\n",
    "        final_memory = psutil.Process(os.getpid()).memory_info().rss / 1e6  # Memory in MB\n",
    "        memory_used = final_memory - initial_memory\n",
    "\n",
    "        mlflow.log_metric(\"runtime\", runtime)\n",
    "        mlflow.log_metric(\"memory_used_MB\", memory_used)\n",
    "\n",
    "        # Log model artifact\n",
    "        mlflow.sklearn.log_model(model, \"random forest, iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/20 20:40:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run rebellious-moth-935 at: http://127.0.0.1:5000/#/experiments/857351534133584674/runs/f362a5af6c95489d827f50b298631494\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/857351534133584674\n"
     ]
    }
   ],
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    config = get_config()\n",
    "    model, accuracy, predictions, y_test, precision, recall, f1 = train_model(config)\n",
    "    log_model_mlflow(config, model, accuracy, predictions, y_test, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'iris Classifier Insights' not found.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# delete the expriment\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "#\n",
    "# Experiment name\n",
    "experiment_name = \"iris Classifier Insights\"\n",
    "\n",
    "# Connect to the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Get the list of Experiments (including deleted)\n",
    "experiments = client.search_experiments(view_type=1)  # 1 = INCLUDE_DELETED\n",
    "\n",
    "# Find the desired experiment\n",
    "experiment = next((exp for exp in experiments if exp.name == experiment_name), None)\n",
    "\n",
    "if experiment:\n",
    "   print(f\"Experiment ID: {experiment.experiment_id} - Status: {experiment.lifecycle_stage}\")\n",
    "\n",
    "    # Experiment recovery...\n",
    "   if experiment.lifecycle_stage == \"deleted\":\n",
    "      print(\"Restoring the experiment...\")\n",
    "      client.restore_experiment(experiment.experiment_id)\n",
    "      print(f\"Experiment '{experiment_name}' restored successfully.\")\n",
    "\n",
    "    # Permanent removal of Experiment\n",
    "      print(\"Deleting the experiment permanently...\")\n",
    "      client.delete_experiment(experiment.experiment_id)\n",
    "      print(f\"Experiment '{experiment_name}' deleted permanently.\")\n",
    "   else:\n",
    "      print(f\"Experiment '{experiment_name}' not found.\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
